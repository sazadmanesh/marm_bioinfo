---
title: "Sample Inventory"
author: "Alicia Rich"
output:
  html_document:
    theme:
      bootswatch: litera
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    code_folding: "show"
    fig_caption: true
    df_print: paged
params:
  sampleset: "loris"
                     
---

```{r, include = FALSE}
global             <- config::get(config = "default")
here::i_am("SampleInventory.Rmd")
source(global$setup)
source(swan$functions)
```


# Intro

This script streamlines and standardizes our handling of the steps taken to reach each dataset from an original sampleset. You will export some standardized csv and tsv tables for easy importing and manipulation with our other workflows.

## Files Needed

To start, you should have four categories of csv files (I download the first three from working google spreadsheets, and the fourth category is a series of files automatically generated by each MinION sequencing run). Those files and their list of column headers to be used are as follows (note: it is fine to have extra columns, but you must at least have these to run the script as is):  

```{r, echo = FALSE}
page_fluid(
    accordion(
      open = FALSE,
      accordion_panel(
        "Show/Hide File List",
        tagList(tagList(
    withTags(
      ol(
        li("Libraries"),
          ul(
            li("SequenceID"),
            li("Pipeline"),
            li("LibraryTube"),
            li("LibraryBarcode"),
            li("ExtractID"),
            li("Final.Library.Concentration"),
            li("Volume.Added.to.Pool.(uL)"),
            li("Seq.ID"),
            li("Run.ID"),
            li("LibraryTubeID")
          ),
        li("Extracts"),
          ul(
            li("ExtractID"),
            li("ExtractDate"),
            li("ExtractedBy"),
            li("ExtractType"),
            li("ExtractKit"),
            li("SampleID"),
            li("ExtractConcentration"),
            li("ExtractBox"),
            li("ExtractNotes")
            ),
        li("Samples"),
          ul(  
            li("SampleID"),
            li("SampleSubject"),
            li("SampleDate"),
            li("SampleCollectedBy"),
            li("SampleNotes")
            ),
        li("Barcode Alignments (1 file per Run.ID)"),
          ul(
            li("barcode"),
            li("alias"),
            li("type"),
            li("target_unclassified"),
            li("qcquisition_run_id"),
            li("protocol_group_id"),
            li("sample_id"),
            li("flow_cell_id"),
            li("started")
            )
        )
      )
    )
    )
    )
    )
    )

```


## Other Configuration Settings

### Sampleset in Params

You can use the sampleset setting under params in the header of this script to select which sampleset you will be working with. So long as the same name is used consistently, this should automatically filter for that name (e.g., loris or marmoset). 

### File Paths

Next, you should make sure your config.yml file contains the path to locate each of the files you will be using. Below is an example excerpt from my config file. 

```{r, echo = FALSE}
page_fluid(
    accordion(
      open = FALSE,
      accordion_panel(
        "Show/Hide External File",
        tagList(tags$pre(includeText("config.yml")))
    )
  )
)
```

Note that I also include paths to files that this script will create. If the file is already there, then it will be overwritten, if not, it will be created there. Run the code below to set up your paths from the config file for the working sampleset you identified in the header:

```{r, echo = FALSE}
page_fluid(
    accordion(
      open = FALSE,
      accordion_panel(
        "Show/Hide External Script",
        tagList(tags$pre(includeText(here(global$setup))))
    )
  )
)
```

### Sequencing Run Lists

The code in the chunk above also generated a list of formatted codes for each available sequencing run to date, separated by taxa/samplesets (currently just for loris and marmoset). Make sure the end number matches the highest integer we have for that sampleset to date.

### Other Setup Scripts

The script that I pasted above sources additional scripts that I run routinely at the start of any work to bring in functions and other inputs with shorter code chunks. You can flip through the text from those scripts below.

```{r, echo = FALSE}
page_fluid(
    accordion(
      title = "Other External Setup Scripts",
      open = FALSE,
      accordion_panel(
        "knit_engines.R",
        tagList(tags$pre(includeText(here(global$knit_engines))))
    ),
      accordion_panel(
        "conflicts.R",
        tagList(tags$pre(includeText(here(global$conflicts))))
    ),
      accordion_panel(
        "functions.R",
        tagList(tags$pre(includeText(here(global$functions))))
    ),
      accordion_panel(
        "packages.R",
        tagList(tags$pre(includeText(here(global$packages))))
    )
  )
)
```



# Script

## Barcode Alignments


```{r, message=FALSE, warning=FALSE}
barcodes <- imap(seqruns, ~ {
  map(.x, ~ read.table(barcode_alignments[[.x]], header = T) %>% mutate(seqrun = .x)) 
}) %>%
    bind_rows() %>%
                        as_tibble() %>%
                        filter(barcode     != "unclassified") %>%
                        mutate(SeqDateTime  = as_datetime(started)) %>%
                        mutate(SeqDate      = floor_date(SeqDateTime, unit = "day")) %>%
                        mutate(SeqRunID     = str_replace_all(sample_id, "pool1", "PL001")) %>%
                      mutate(LibraryCode    = str_squish(str_trim(seqrun      , "both")),
                             FlowCellSerial = str_squish(str_trim(flow_cell_id, "both"))
                             ) %>%
                      mutate(LibraryBarcode  = as.numeric(str_remove_all(barcode, "16S|barcode0|barcode"))) %>%
                        select(LibraryCode,
                               LibraryBarcode,
                               reads_unclassified = target_unclassified,
                               FlowCellSerial,
                               protocol_group_id,
                               SeqRunID,
                               SeqDate,
                               SeqDateTime)

write.table(barcodes, barcode_alignments$compilations[[paste0(params$sampleset)]],
            row.names = F,
            sep = "\t")
```

## Sequencing Runs

```{r, message=FALSE, warning=FALSE}
seqrun.tbl <- read.csv(here(path$inventories$seqruns), header = T) %>% 
  mutate(SampleSet       = if_else(str_detect(Pooled.Library.Code, "CM"), "marmoset", "loris"),
         LibraryCode     = str_to_lower(Pooled.Library.Code),
         LibPrepWorkflow = case_when(
           str_detect(Kit, "LSK") & Pipeline == "16S" ~ "lsk16s",
           Pipeline == "Host mtDNA"                   ~ "lskadaptive",
           str_detect(Kit, "SQK-16S") & Pipeline == "16S" ~ "rapid16s"),
         LibPrepDate     = mdy(Run.Date),
         SeqRunDate      = ymd(str_remove_all(str_trim(Run.ID, "both"), "MIN_16_|MIN_16-|MIN_MT_"))) %>%
  mutate(LibraryCode     = str_replace_all(LibraryCode, "pl00|pl0", "hdz"),
         strands         = 2,
         fragment_type   = if_else(Pipeline == "16S", 3, 1),
         Length          = if_else(Pipeline == "16S", 1500, 10000),
         InputMassStart  = if_else(Pipeline == "16S", 10, 1000),
         TemplateVolPrep = if_else(LibPrepWorkflow == "rapid16s", 15, 47),
         PoolSamples     = if_else(Pipeline == "16S", "yes", "no"),
         InputMassFinal  = 50
         ) %>%
  filter(SampleSet == params$sampleset) %>%
  select(
         SampleSet,
         LibraryCode,
         LibPrepDate,
         LibPrepWorkflow,
         LibPrepKit      = Kit,
         FlowCellSerial  = Flow.Cell.ID,
         FlowCellType    = Flow.Cell.Type,
         FlongleAdapter  = Flongle.Adapter,
         SeqDevice       = Sequencer,
         strands,
         fragment_type,
         Length,
         InputMassStart,
         TemplateVolPrep,
         PoolSamples,
         InputMassFinal)
```


## Sample Records

```{r, warning = FALSE}
samples     <- read.csv(here(path$inventories$collection), 
                        header = T) %>% 
                      filter(str_starts(SampleID, "\\w+")) %>% 
                      select(-SampleBox)  %>%
                      mutate(SampleID = str_squish(str_trim(SampleID, "both"))) %>% distinct() %>%
                      mutate(CollectionDate     = mdy(SampleDate),
                             Subject            = str_squish(str_trim(SampleSubject)),
                             .keep = "unused") %>% distinct() %>%
                      mutate(Subj_Certainty = if_else(Subject %in% subject_list, "yes", "no")) %>%
                      mutate(Subject        = str_remove_all(Subject, "\\?"))
```

## DNA Extract Records

We will also join the previous sample records to this table at the end of the chunk.

```{r}
extracts <- read.csv(here(path$inventories$extraction), 
                     header = T) %>% 
  filter(str_starts(SampleID, "\\w+")) %>%
  mutate(SampleID        = if_else(str_detect(SampleID, "#N/A"), "ExtractControl", SampleID)) %>%
  mutate(SampleID = str_squish(str_trim(SampleID, "both")),
         ExtractID= str_squish(str_trim(ExtractID, "both")),
         ExtractDate       = mdy(ExtractDate)) %>%
  mutate(ExtractConc       = str_remove_all(ExtractConcentration, ">"), .keep = "unused") %>%
  mutate(ExtractConc = if_else(str_detect(ExtractConc, "Higher"), "100", ExtractConc),
         ExtractConc = if_else(str_detect(ExtractConc, "HIGHER"), "100", ExtractConc),
         ExtractConc = if_else(ExtractConc == "LOW", "0", ExtractConc),
         ExtractConc = if_else(ExtractConc == "", NA, ExtractConc)) %>%
  mutate(ExtractConc = round(as.numeric(ExtractConc), 1))  %>% filter(ExtractType == "DNA") %>%
  select(-ExtractType) %>%
  right_join(samples) %>% distinct()
```

## Libraries and Combining all Records

```{r}
compilation <- read.csv(here(path$inventories$libraries), 
                        header = T)  %>% 
  filter(str_starts(SequenceID, "\\w+") & Seq.ID != "#N/A") %>%
  mutate(LibraryCode     = str_to_lower(Seq.ID)) %>%
  mutate(LibraryCode     = str_replace_all(LibraryCode, "pl00|pl0" , "hdz"),
         SampVolPool     = round(as.numeric(Volume.Added.to.Pool..uL.), 0),
         LibraryBarcode  = as.numeric(str_remove_all(LibraryBarcode, "16S|barcode0|barcode"))) %>%
  mutate(TotalPoolVol    = sum(SampVolPool), .by = LibraryCode) %>%
  mutate(BeadVol         = TotalPoolVol * 0.6) %>%
  select(SequenceID,
         LibraryCode,
         LibraryTube,
         LibraryBarcode,
         ExtractID,
         SampVolPool,
         TotalPoolVol,
         BeadVol,
         Conc_QC2    = Final.Library.Concentration) %>%
  full_join(barcodes, by = join_by(LibraryCode, LibraryBarcode)) %>%
  left_join(seqrun.tbl, by = join_by(LibraryCode, FlowCellSerial)) %>%
  right_join(extracts, by = join_by(ExtractID)) %>% distinct() %>%
  mutate(steps_remaining = case_when(
    is.na(ExtractID) ~ "sample not extracted",
    is.na(SequenceID) ~ "extract not sequenced",
    !is.na(ExtractID) & !is.na(SequenceID) & !is.na(SampleID) ~ "sample extracted and sequenced"
  )) %>%
  relocate(SampleID, ExtractID, SequenceID, steps_remaining) %>%
  arrange(CollectionDate, Subject)
```

### Exporting a Spreadsheet with Records

We will use this spreadsheet for building the metadata table but also for calling up sample info in our protocol apps.

```{r, message=FALSE, warning=FALSE}
write.table(compilation,
            here(path$inventories$all_stages),
            row.names = F,
            sep = "\t")
```


## Counting Replicates

```{r}
count.extracts    <- extracts %>% select(ExtractID, SampleID) %>% distinct() %>% 
  group_by(SampleID)  %>% 
  mutate(n_dna_extracts = n_distinct(ExtractID)) %>% ungroup() %>% select(-ExtractID)

count.libraries <- compilation %>% select(SequenceID, ExtractID, SampleID) %>% distinct() %>% 
  group_by(ExtractID) %>% mutate(n_16s_extract = n_distinct(SequenceID)) %>% ungroup() %>%
  group_by(SampleID)  %>% mutate(n_16s_sample  = n_distinct(SequenceID)) %>% ungroup() %>% select(-SequenceID)
```

## Exporting SampleSheets formatted for Dorado

```{r, message=FALSE, warning=FALSE}
samplesheet <- compilation %>%
  filter(steps_remaining == "sample extracted and sequenced") %>%
                      mutate(barcode = if_else(LibraryBarcode < 10, 
                                               str_glue("barcode0", "{LibraryBarcode}"),
                                               str_glue("barcode" , "{LibraryBarcode}"))) %>%
                      select(flow_cell_id  = FlowCellSerial,
                             experiment_id = protocol_group_id,
                             kit           = LibPrepKit,
                             barcode,
                             alias         = SequenceID,
                             seqrun        = LibraryCode)

write.table(samplesheet, 
          sample_sheets$compilations[[paste0(params$sampleset)]],
          row.names = F,
          quote     = F,
          sep       = ",")
```

### Splitting Samplesheet to Individual Files for Each Run


```{r}
samplesheet.nested <- samplesheet %>% nest(.by = seqrun) %>%
  deframe()
```


```{r, include = FALSE}
imap(samplesheet.nested, ~ {
  write.table(.x, (sample_sheets[[.y]]),
          row.names = F,
          quote     = F,
          sep       = ",")
})
```



# Next Step

>Now you should proceed to the Read Processing workflow to begin basecalling the sequencing run.
